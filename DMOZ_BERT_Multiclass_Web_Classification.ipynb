{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Multiclass Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/MachineLearning/blob/master/DMOZ_BERT_Multiclass_Web_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LodY-iiDCqf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYR_I0f4Cs8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQk2Gej4Cz8s",
        "colab_type": "code",
        "outputId": "5c673c58-dd87-42cc-ee68-1f34b3d7438f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "%%bash\n",
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.32)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.32)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch-pretrained-bert) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44U7Z2tnC2tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    testing=True,\n",
        "    bert_model_name=\"bert-base-uncased\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=4,\n",
        "    use_fp16=True,\n",
        "    bs=32,\n",
        "    discriminative=False,\n",
        "    max_seq_len=256,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PzCgJfJC--k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "bert_tok = BertTokenizer.from_pretrained(\n",
        "    config.bert_model_name,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR7FW97-DDF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _join_texts(texts:Collection[str], mark_fields:bool=False, sos_token:Optional[str]=BOS):\n",
        "    \"\"\"Borrowed from fast.ai source\"\"\"\n",
        "    if not isinstance(texts, np.ndarray): texts = np.array(texts)\n",
        "    if is1d(texts): texts = texts[:,None]\n",
        "    df = pd.DataFrame({i:texts[:,i] for i in range(texts.shape[1])})\n",
        "    text_col = f'{FLD} {1} ' + df[0].astype(str) if mark_fields else df[0].astype(str)\n",
        "    if sos_token is not None: text_col = f\"{sos_token} \" + text_col\n",
        "    for i in range(1,len(df.columns)):\n",
        "        #text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i]\n",
        "        text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i].astype(str)\n",
        "    return text_col.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8grIYq1DKA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1S-kdzwDZa7",
        "colab_type": "code",
        "outputId": "ff592494-faa4-4d98-aa4d-10400d81043c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOproF2LDPbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # DATA_ROOT = Path(\"..\") / \"input\"\n",
        "# DATA_ROOT=Path('/content/drive/My Drive/Data/DMOZ')\n",
        "# df = pd.read_csv(DATA_ROOT / \"train.csv\")\n",
        "# # train, test = [pd.read_csv(DATA_ROOT / fname,sep='\\t') for fname in [\"train1.csv\", \"test1.csv\"]]\n",
        "# # val = train # we won't be using a validation set but you can easily create one using train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv_YfqzecYK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try:\n",
        "#   df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "# except:\n",
        "#   pass\n",
        "# df.dropna(inplace=True)\n",
        "# df['cat_id']=df['cat_id'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEWNN7WSSVPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample=False\n",
        "DATA_ROOT=Path('/content/drive/My Drive/Data/DMOZ')\n",
        "df = pd.read_csv(DATA_ROOT / \"train.csv\")\n",
        "try:\n",
        "  df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "except:\n",
        "  pass\n",
        "df.dropna(inplace=True)\n",
        "df['cat_id']=df['cat_id'].astype(int)\n",
        "if sample==True:\n",
        "  df_sample=df[df['cat_id']<9]\n",
        "  train=pd.concat([df_sample,pd.get_dummies(df_sample['cat_id'], prefix='label')],axis=1)\n",
        "  df=df_sample\n",
        "else:  \n",
        "  # train=df \n",
        "  train=pd.concat([df,pd.get_dummies(df['cat_id'], prefix='label')],axis=1) \n",
        "val=train\n",
        "\n",
        "del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8ie9O4knreG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_labels=df['cat_id'].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs7WBq6elLsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df[df['cat_id']<10]['cat_id'].value_counts()\n",
        "# df_sample=df[df['cat_id']<9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCHC3F5VGIPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train=pd.concat([df,pd.get_dummies(df['cat_id'], prefix='label')],axis=1)\n",
        "# train=pd.concat([df_sample,pd.get_dummies(df_sample['cat_id'], prefix='label')],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P3wVYMsK48s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train, test = train_test_split(train, random_state=42, test_size=0.33, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6wEWV05KnP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val=train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iztsvs7_I8rT",
        "colab_type": "code",
        "outputId": "463fc932-10dd-491f-875f-4c5cb0ac2dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.cat_id.unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1, 100, 101, 103, ...,  96,  97,  98,  99])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp_1iUAVl5to",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols=[]\n",
        "text='Top Stories After Huge Win, Boris Johnson Promises Brexit By Jan 31, \"No Ifs, No Buts\" States Not Empowered To Block Citizenship Act, Say Government Sources Spent 66% Of Rs 3.38 Lakh Crore Budgeted Expenditure: Economic Advisor \\'PM Should Apologise\\': Rahul Gandhi Tweets Video Amid \"Rape In India\" Row \"Won\\'t Apologise,\" Says Rahul Gandhi Amid Row Over \"Rape In India\" Remark Watch: Sri Lanka Player\\'s Hilarious Response To Pakistan Journalist More cricket Trending Watch: Steve \"Flying\" Smith Takes One Of The Best Catches You\\'ll Ever See Reviews More Gadgets Reviews Samsung Galaxy A50, Galaxy A70, Galaxy S9 समत कई समसग समरटफन पर बपर डसकउट Samsung Galaxy M11 और Galaxy M31 अगल सल ह सकत ह लनच चर रयर कमर वल Samsung Galaxy A71 और Samsung Galaxy A51 लनच WhatsApp अगल सल स कई समरटफन पर नह करग कम PUBG Mobile in India May Get Privacy Destroying Features Will Nintendo\\'s New Switch Consoles Be Better than the PS4 Pro?', 'Tamil Tamil परवततर म CAB क खलफ हसक परदरशन, गवहट म पलस क फयरग म 2 लग क मत गर BJP शसत रजय म CAB क वरध शर, अब पजब क सएम अमरदर सह न कह- बल असवधनक Aus Vs NZ: टम सउद न मर बललबज क गद, बच म भड गए वरनर, बल- \\'उसक हथ म लग ह...\\' दख Video UK Elections: एगजट पल म पएम बरस जनसन क कजरवटव परट क सपषट बहमत Bravo \"Excited About Comeback\" After Return To International Cricket Steven Gerrard Signs New Deal At Rangers Until 2024 Greenwood Stars As Man United Top Group, Arsenal Draw In Europa League November Trade Deficit Narrows To $12.', '12 Billion Food Bangladesh Asks India To Increase Guwahati Mission Security Amid Protests தமழ சனம நடகர சததரத அமசசர ஜயகமரகக பதலட..!', 'இநத வரம வளயகம எககசசகக தமழ படஙகள..!', \"வபவ-இன டண' பட ரலஸ தத அறவபப..!\", 'ஜய-அதலய ரவ ஜட சரம இரணடவத படம..!', 'டடடல வளயடட வறறமறன..!', 'Osteoporosis - Love your Bones Follow These Amazing Tips By Dr Kiran Lohia To Prevent Acne Breakouts Offbeat Baby Yoda To Disappointed Pakistani Fan: A Look At The Best Memes Of 2019 Biggest Parliament Majority For Boris Johnson\\'s Party Since Thatcher Days South News No Top Court Order On Plea Of 2 Women For Protection To Enter Sabarimala Cities Nearly 7,000 Trees To Be Cut For Jewar Airport In Uttar Pradesh \"We Have Been Cheated...\": Teachers After Left Out Of Recruitment Process Campaigns 60,000 Blankets Needed: Help Save Lives, Donate A Blanket For The Homeless, Here\\'s How Fighting Our Killer Air Pollution: Check The Air Quality Index Of Your City Chhattisgarh Becomes The Most Efficient State In Waste Management: Government A Startup In Uttarakhand Develops An Eco-Friendly Sanitary Pad That Lasts Five Times Longer Than Regular Pads'\n",
        "\n",
        "num_labels=train['cat_id'].nunique()\n",
        "\n",
        "data={'cat_id':[0],\n",
        "      'category':[text],\n",
        "}\n",
        "test=pd.DataFrame(data)\n",
        "for labels in train['cat_id'].unique():\n",
        "  label='label_'+str(labels)\n",
        "  label_cols.append(label)\n",
        "  test[label]=0\n",
        "\n",
        "test=test.append(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHUcwrpYhzAP",
        "colab_type": "code",
        "outputId": "bca7aa27-eb5e-44f0-f0a9-48989c0304bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "test.sample()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat_id</th>\n",
              "      <th>category</th>\n",
              "      <th>label_1</th>\n",
              "      <th>label_100</th>\n",
              "      <th>label_101</th>\n",
              "      <th>label_103</th>\n",
              "      <th>label_104</th>\n",
              "      <th>label_105</th>\n",
              "      <th>label_106</th>\n",
              "      <th>label_107</th>\n",
              "      <th>label_108</th>\n",
              "      <th>label_109</th>\n",
              "      <th>label_11</th>\n",
              "      <th>label_110</th>\n",
              "      <th>label_111</th>\n",
              "      <th>label_112</th>\n",
              "      <th>label_113</th>\n",
              "      <th>label_114</th>\n",
              "      <th>label_115</th>\n",
              "      <th>label_116</th>\n",
              "      <th>label_117</th>\n",
              "      <th>label_118</th>\n",
              "      <th>label_119</th>\n",
              "      <th>label_12</th>\n",
              "      <th>label_120</th>\n",
              "      <th>label_122</th>\n",
              "      <th>label_123</th>\n",
              "      <th>label_124</th>\n",
              "      <th>label_125</th>\n",
              "      <th>label_126</th>\n",
              "      <th>label_127</th>\n",
              "      <th>label_129</th>\n",
              "      <th>label_13</th>\n",
              "      <th>label_130</th>\n",
              "      <th>label_131</th>\n",
              "      <th>label_133</th>\n",
              "      <th>label_134</th>\n",
              "      <th>label_135</th>\n",
              "      <th>label_136</th>\n",
              "      <th>label_137</th>\n",
              "      <th>...</th>\n",
              "      <th>label_62</th>\n",
              "      <th>label_63</th>\n",
              "      <th>label_64</th>\n",
              "      <th>label_65</th>\n",
              "      <th>label_66</th>\n",
              "      <th>label_67</th>\n",
              "      <th>label_68</th>\n",
              "      <th>label_69</th>\n",
              "      <th>label_7</th>\n",
              "      <th>label_70</th>\n",
              "      <th>label_71</th>\n",
              "      <th>label_72</th>\n",
              "      <th>label_73</th>\n",
              "      <th>label_74</th>\n",
              "      <th>label_75</th>\n",
              "      <th>label_76</th>\n",
              "      <th>label_77</th>\n",
              "      <th>label_78</th>\n",
              "      <th>label_79</th>\n",
              "      <th>label_8</th>\n",
              "      <th>label_80</th>\n",
              "      <th>label_81</th>\n",
              "      <th>label_83</th>\n",
              "      <th>label_84</th>\n",
              "      <th>label_85</th>\n",
              "      <th>label_86</th>\n",
              "      <th>label_87</th>\n",
              "      <th>label_88</th>\n",
              "      <th>label_89</th>\n",
              "      <th>label_9</th>\n",
              "      <th>label_90</th>\n",
              "      <th>label_91</th>\n",
              "      <th>label_92</th>\n",
              "      <th>label_93</th>\n",
              "      <th>label_94</th>\n",
              "      <th>label_95</th>\n",
              "      <th>label_96</th>\n",
              "      <th>label_97</th>\n",
              "      <th>label_98</th>\n",
              "      <th>label_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>(Top Stories After Huge Win, Boris Johnson Pro...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 538 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cat_id  ... label_99\n",
              "0       0  ...        0\n",
              "\n",
              "[1 rows x 538 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFpRRHrtDyE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config.testing:\n",
        "    train = train.head(1024)\n",
        "    val = val.head(1024)\n",
        "    test = test.head(1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMaHAzD4EDYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB6qLQkyEIWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3be4CzHIL6HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols=train.columns\n",
        "label_cols[2:]\n",
        "label_cols = label_cols[2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8YcFjOoPPXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols=[str(item) for item in label_cols]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljEqJGemPr0l",
        "colab_type": "code",
        "outputId": "36ca2094-919b-4f32-f56e-d72993c430e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_cols[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'label_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm9FR2GxEK_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow8Yle5HEP6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for BERT\n",
        "    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original BERT model.\n",
        "    \"\"\"\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),NumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1LmKYwZEUs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
        "                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
        "                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n",
        "        \"Create a `TextDataBunch` from DataFrames.\"\n",
        "        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n",
        "        # use our custom processors while taking tokenizer and vocab as kwargs\n",
        "        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n",
        "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
        "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
        "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
        "        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n",
        "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
        "        return src.databunch(**kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v54gMXuEbaz",
        "colab_type": "code",
        "outputId": "3021f07a-600d-4e62-f1fd-c5646e83f112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "databunch = BertDataBunch.from_df(\".\", train, val, test,\n",
        "                  tokenizer=fastai_tokenizer,\n",
        "                  vocab=fastai_bert_vocab,\n",
        "                  text_cols=\"category\",\n",
        "                  label_cols=label_cols,\n",
        "                  bs=config.bs,\n",
        "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gx2ERYwEgyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\n",
        "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBtzsoVxF2HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rugTTOPAF6PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import *\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "learner = Learner(\n",
        "    databunch, bert_model,\n",
        "    loss_func=loss_func\n",
        ")\n",
        "if config.use_fp16: learner = learner.to_fp16()\n",
        "# learner.to_fp32()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJ-n679oVYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMD5cHmDF-Q8",
        "colab_type": "code",
        "outputId": "153dcdfc-550f-4385-f447-a4c10334bb4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wrwGvyxnt0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learner.destroy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHa33A7-GAzE",
        "colab_type": "code",
        "outputId": "01f0873a-ce60-4a88-e3e1-d36218c86ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "learner.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmfwMZrGEHr",
        "colab_type": "code",
        "outputId": "f6107f07-c323-468f-edc1-666106047fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# learner.fit_one_cycle(config.epochs, max_lr=config.max_lr)\n",
        "# learner.fit_one_cycle(config.epochs, max_lr=1e-02)\n",
        "learner.fit_one_cycle(8, max_lr=config.max_lr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.685904</td>\n",
              "      <td>0.654332</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.602281</td>\n",
              "      <td>0.448875</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.456354</td>\n",
              "      <td>0.256385</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.326500</td>\n",
              "      <td>0.163394</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.234353</td>\n",
              "      <td>0.120974</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.174762</td>\n",
              "      <td>0.102022</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.138631</td>\n",
              "      <td>0.095093</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.118299</td>\n",
              "      <td>0.094011</td>\n",
              "      <td>03:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YtM9FwbhpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learner.save(file=DATA_ROOT/'Model_DMOZ(all_cat_v1_2).pkl')\n",
        "learner.export(file=DATA_ROOT/'Export_Model_DMOZ_1.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK-KciHgGLMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnHEIDX3GRbz",
        "colab_type": "code",
        "outputId": "bed7a870-047d-41b4-e62b-7558fab175d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# learner.load(file=DATA_ROOT/'model1.pkl')\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vviaLNkeGVB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample_submission = pd.read_csv(DATA_ROOT / \"sample_submission.csv\")\n",
        "# if config.testing: sample_submission = sample_submission.head(test.shape[0])\n",
        "# sample_submission[label_cols] = test_preds\n",
        "# sample_submission.to_csv(DATA_ROOT /\"predictions.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owGBzah1hJYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission=test\n",
        "for label in label_cols:\n",
        "  sample_submission[label]=0\n",
        "sample_submission[label_cols] = test_preds\n",
        "# sample_submission.to_csv(DATA_ROOT /\"predictions_1.csv\", index=False)\n",
        "# sample_submission.sample(10000).to_csv(DATA_ROOT /\"predictions_sample.csv\", index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kcSoj_dt_yT",
        "colab_type": "code",
        "outputId": "8c8632f8-ced3-4e6a-b49e-fb825a9de709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "sample_submission.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat_id</th>\n",
              "      <th>category</th>\n",
              "      <th>label_1</th>\n",
              "      <th>label_100</th>\n",
              "      <th>label_101</th>\n",
              "      <th>label_103</th>\n",
              "      <th>label_104</th>\n",
              "      <th>label_105</th>\n",
              "      <th>label_106</th>\n",
              "      <th>label_107</th>\n",
              "      <th>label_108</th>\n",
              "      <th>label_109</th>\n",
              "      <th>label_11</th>\n",
              "      <th>label_110</th>\n",
              "      <th>label_111</th>\n",
              "      <th>label_112</th>\n",
              "      <th>label_113</th>\n",
              "      <th>label_114</th>\n",
              "      <th>label_115</th>\n",
              "      <th>label_116</th>\n",
              "      <th>label_117</th>\n",
              "      <th>label_118</th>\n",
              "      <th>label_119</th>\n",
              "      <th>label_12</th>\n",
              "      <th>label_120</th>\n",
              "      <th>label_122</th>\n",
              "      <th>label_123</th>\n",
              "      <th>label_124</th>\n",
              "      <th>label_125</th>\n",
              "      <th>label_126</th>\n",
              "      <th>label_127</th>\n",
              "      <th>label_129</th>\n",
              "      <th>label_13</th>\n",
              "      <th>label_130</th>\n",
              "      <th>label_131</th>\n",
              "      <th>label_133</th>\n",
              "      <th>label_134</th>\n",
              "      <th>label_135</th>\n",
              "      <th>label_136</th>\n",
              "      <th>label_137</th>\n",
              "      <th>...</th>\n",
              "      <th>label_62</th>\n",
              "      <th>label_63</th>\n",
              "      <th>label_64</th>\n",
              "      <th>label_65</th>\n",
              "      <th>label_66</th>\n",
              "      <th>label_67</th>\n",
              "      <th>label_68</th>\n",
              "      <th>label_69</th>\n",
              "      <th>label_7</th>\n",
              "      <th>label_70</th>\n",
              "      <th>label_71</th>\n",
              "      <th>label_72</th>\n",
              "      <th>label_73</th>\n",
              "      <th>label_74</th>\n",
              "      <th>label_75</th>\n",
              "      <th>label_76</th>\n",
              "      <th>label_77</th>\n",
              "      <th>label_78</th>\n",
              "      <th>label_79</th>\n",
              "      <th>label_8</th>\n",
              "      <th>label_80</th>\n",
              "      <th>label_81</th>\n",
              "      <th>label_83</th>\n",
              "      <th>label_84</th>\n",
              "      <th>label_85</th>\n",
              "      <th>label_86</th>\n",
              "      <th>label_87</th>\n",
              "      <th>label_88</th>\n",
              "      <th>label_89</th>\n",
              "      <th>label_9</th>\n",
              "      <th>label_90</th>\n",
              "      <th>label_91</th>\n",
              "      <th>label_92</th>\n",
              "      <th>label_93</th>\n",
              "      <th>label_94</th>\n",
              "      <th>label_95</th>\n",
              "      <th>label_96</th>\n",
              "      <th>label_97</th>\n",
              "      <th>label_98</th>\n",
              "      <th>label_99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>(Top Stories After Huge Win, Boris Johnson Pro...</td>\n",
              "      <td>0.571109</td>\n",
              "      <td>0.216674</td>\n",
              "      <td>0.205137</td>\n",
              "      <td>0.059319</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.085251</td>\n",
              "      <td>0.086478</td>\n",
              "      <td>0.063019</td>\n",
              "      <td>0.135346</td>\n",
              "      <td>0.134208</td>\n",
              "      <td>0.121686</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.061876</td>\n",
              "      <td>0.089933</td>\n",
              "      <td>0.125493</td>\n",
              "      <td>0.055618</td>\n",
              "      <td>0.048316</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.056757</td>\n",
              "      <td>0.062331</td>\n",
              "      <td>0.065366</td>\n",
              "      <td>0.095856</td>\n",
              "      <td>0.125386</td>\n",
              "      <td>0.094845</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.075448</td>\n",
              "      <td>0.107437</td>\n",
              "      <td>0.08389</td>\n",
              "      <td>0.096365</td>\n",
              "      <td>0.132402</td>\n",
              "      <td>0.06489</td>\n",
              "      <td>0.074097</td>\n",
              "      <td>0.115961</td>\n",
              "      <td>0.084947</td>\n",
              "      <td>0.13229</td>\n",
              "      <td>0.115761</td>\n",
              "      <td>0.093182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129623</td>\n",
              "      <td>0.109897</td>\n",
              "      <td>0.060529</td>\n",
              "      <td>0.076546</td>\n",
              "      <td>0.081666</td>\n",
              "      <td>0.049589</td>\n",
              "      <td>0.190875</td>\n",
              "      <td>0.074231</td>\n",
              "      <td>0.090735</td>\n",
              "      <td>0.0771</td>\n",
              "      <td>0.081082</td>\n",
              "      <td>0.0537</td>\n",
              "      <td>0.057918</td>\n",
              "      <td>0.109135</td>\n",
              "      <td>0.083441</td>\n",
              "      <td>0.173148</td>\n",
              "      <td>0.062103</td>\n",
              "      <td>0.06804</td>\n",
              "      <td>0.075995</td>\n",
              "      <td>0.112991</td>\n",
              "      <td>0.050331</td>\n",
              "      <td>0.055926</td>\n",
              "      <td>0.069922</td>\n",
              "      <td>0.082549</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.133077</td>\n",
              "      <td>0.077378</td>\n",
              "      <td>0.07383</td>\n",
              "      <td>0.074231</td>\n",
              "      <td>0.073963</td>\n",
              "      <td>0.066448</td>\n",
              "      <td>0.077938</td>\n",
              "      <td>0.143068</td>\n",
              "      <td>0.104295</td>\n",
              "      <td>0.067547</td>\n",
              "      <td>0.063948</td>\n",
              "      <td>0.110088</td>\n",
              "      <td>0.079926</td>\n",
              "      <td>0.111434</td>\n",
              "      <td>0.076684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>(Top Stories After Huge Win, Boris Johnson Pro...</td>\n",
              "      <td>0.571109</td>\n",
              "      <td>0.216674</td>\n",
              "      <td>0.205137</td>\n",
              "      <td>0.059319</td>\n",
              "      <td>0.050894</td>\n",
              "      <td>0.085251</td>\n",
              "      <td>0.086478</td>\n",
              "      <td>0.063019</td>\n",
              "      <td>0.135346</td>\n",
              "      <td>0.134208</td>\n",
              "      <td>0.121686</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.061876</td>\n",
              "      <td>0.089933</td>\n",
              "      <td>0.125493</td>\n",
              "      <td>0.055618</td>\n",
              "      <td>0.048316</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.056757</td>\n",
              "      <td>0.062331</td>\n",
              "      <td>0.065366</td>\n",
              "      <td>0.095856</td>\n",
              "      <td>0.125386</td>\n",
              "      <td>0.094845</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.075448</td>\n",
              "      <td>0.107437</td>\n",
              "      <td>0.08389</td>\n",
              "      <td>0.096365</td>\n",
              "      <td>0.132402</td>\n",
              "      <td>0.06489</td>\n",
              "      <td>0.074097</td>\n",
              "      <td>0.115961</td>\n",
              "      <td>0.084947</td>\n",
              "      <td>0.13229</td>\n",
              "      <td>0.115761</td>\n",
              "      <td>0.093182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.129623</td>\n",
              "      <td>0.109897</td>\n",
              "      <td>0.060529</td>\n",
              "      <td>0.076546</td>\n",
              "      <td>0.081666</td>\n",
              "      <td>0.049589</td>\n",
              "      <td>0.190875</td>\n",
              "      <td>0.074231</td>\n",
              "      <td>0.090735</td>\n",
              "      <td>0.0771</td>\n",
              "      <td>0.081082</td>\n",
              "      <td>0.0537</td>\n",
              "      <td>0.057918</td>\n",
              "      <td>0.109135</td>\n",
              "      <td>0.083441</td>\n",
              "      <td>0.173148</td>\n",
              "      <td>0.062103</td>\n",
              "      <td>0.06804</td>\n",
              "      <td>0.075995</td>\n",
              "      <td>0.112991</td>\n",
              "      <td>0.050331</td>\n",
              "      <td>0.055926</td>\n",
              "      <td>0.069922</td>\n",
              "      <td>0.082549</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.133077</td>\n",
              "      <td>0.077378</td>\n",
              "      <td>0.07383</td>\n",
              "      <td>0.074231</td>\n",
              "      <td>0.073963</td>\n",
              "      <td>0.066448</td>\n",
              "      <td>0.077938</td>\n",
              "      <td>0.143068</td>\n",
              "      <td>0.104295</td>\n",
              "      <td>0.067547</td>\n",
              "      <td>0.063948</td>\n",
              "      <td>0.110088</td>\n",
              "      <td>0.079926</td>\n",
              "      <td>0.111434</td>\n",
              "      <td>0.076684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 538 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cat_id  ...  label_99\n",
              "0       0  ...  0.076684\n",
              "0       0  ...  0.076684\n",
              "\n",
              "[2 rows x 538 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VridZWQGIwqP",
        "colab_type": "code",
        "outputId": "96a32aba-f7f4-4697-9826-6dbdd98fd476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "output=sample_submission.head(1).drop(columns=['cat_id','category']).T\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label_1</th>\n",
              "      <td>0.571109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_100</th>\n",
              "      <td>0.216674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_101</th>\n",
              "      <td>0.205137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_103</th>\n",
              "      <td>0.059319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_104</th>\n",
              "      <td>0.050894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_95</th>\n",
              "      <td>0.063948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_96</th>\n",
              "      <td>0.110088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_97</th>\n",
              "      <td>0.079926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_98</th>\n",
              "      <td>0.111434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_99</th>\n",
              "      <td>0.076684</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>536 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "label_1    0.571109\n",
              "label_100  0.216674\n",
              "label_101  0.205137\n",
              "label_103  0.059319\n",
              "label_104  0.050894\n",
              "...             ...\n",
              "label_95   0.063948\n",
              "label_96   0.110088\n",
              "label_97   0.079926\n",
              "label_98   0.111434\n",
              "label_99   0.076684\n",
              "\n",
              "[536 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb1Ex3gjI4Qk",
        "colab_type": "code",
        "outputId": "92d4db72-e8f6-411c-86c8-cf897f03773e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "output[0]=output[0].astype(float)\n",
        "output.nlargest(5,[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label_1</th>\n",
              "      <td>0.571109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_100</th>\n",
              "      <td>0.216674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_40</th>\n",
              "      <td>0.214198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_238</th>\n",
              "      <td>0.206094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_101</th>\n",
              "      <td>0.205137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "label_1    0.571109\n",
              "label_100  0.216674\n",
              "label_40   0.214198\n",
              "label_238  0.206094\n",
              "label_101  0.205137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qIkX6fVlZgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.to_csv(DATA_ROOT /\"predictions_test.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2oIINu7GZFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learner.export(file=DATA_ROOT /\"Model1.pkl\")\n",
        "# learner.save(file=DATA_ROOT/'Final_Model_BERT.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UvKZ30gQCYM",
        "colab_type": "code",
        "outputId": "d412bc8b-f9c3-43a3-cdde-3bf9641f3c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learner.validate()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09401108]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seVv89QIiqEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text='Efforts were being made on Friday to help passengers stranded at the airport, railway station and inter-state bus terminals in Guwahati, an official said.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp6NbEjgsyOm",
        "colab_type": "code",
        "outputId": "0bc214dd-925c-4cbb-b944-bdbdd29cfdd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x=learner.predict(text)\n",
        "y=pd.DataFrame(x[2],index=label_cols)\n",
        "# x[2].shape\n",
        "y.nlargest(5,[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label_1</th>\n",
              "      <td>0.573499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_100</th>\n",
              "      <td>0.220175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_40</th>\n",
              "      <td>0.216012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_101</th>\n",
              "      <td>0.210766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_238</th>\n",
              "      <td>0.204978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "label_1    0.573499\n",
              "label_100  0.220175\n",
              "label_40   0.216012\n",
              "label_101  0.210766\n",
              "label_238  0.204978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZIFzEC8cOFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Neslg0FBDlkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}