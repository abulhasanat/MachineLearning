{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import nltk.classify\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "import nltk \n",
    "from nltk import NaiveBayesClassifier as nbc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "training_data=[('I love this sandwich!', 'pos'),\n",
    "('This is an amazing place!', 'pos'),\n",
    "('I feel very good about these beers.', 'pos'),\n",
    "('This is my best work!', 'pos'),\n",
    "(\"What an awesome view\", 'pos'),\n",
    "('System down!', 'neg'),\n",
    "('I shall visit my home next month', 'pos'),               \n",
    "('I do not like this restaurant', 'neg'),\n",
    "('I am tired of this stuff.', 'neg'),\n",
    "(\"I can't deal with this\", 'neg'),\n",
    "('He is my sworn enemy!', 'neg'),\n",
    "('This figure is not correct!', 'neg'),\n",
    "('The movie is horrible.', 'neg'),\n",
    "('Ram is my best friend.','pos'),\n",
    "(\"That's a horrible place!\",'neg'),\n",
    "(\"Aman is going to US\",'pos')]\n",
    "\n",
    "\n",
    "# Test data\n",
    "test = [('The beer was good.', 'pos'),\n",
    "        ('I do not enjoy my job', 'neg'),\n",
    "        (\"I ain't feeling dandy today.\", 'neg'),\n",
    "        (\"I feel amazing!\", 'pos'),\n",
    "        ('Gary is a friend of mine.', 'pos'),\n",
    "        (\"I can't believe I'm doing this.\", 'neg'),\n",
    "       (\"I can't go.\",'neg')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features\n",
    "vocabulary = set(chain(*[word_tokenize(i[0].lower()) for i in training_data]))\n",
    "feature_set = [({i:(i in word_tokenize(sentence.lower())) for i in vocabulary if not i in stop_words},tag) for sentence, tag in training_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nbc.train(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "featurized_test_sentence = [({i:(i in word_tokenize(sentence.lower())) for i in vocabulary if not i in stop_words},tag) for sentence,tag in test]\n",
    "print(\"Accuracy: {}\".format(nltk.classify.accuracy(classifier,featurized_test_sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random testing with confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend: pos, confidence: 81%\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"Ramu'll visit Delhi.\"\n",
    "featurized_test_sentence =  {i:(i in word_tokenize(test_sentence.lower())) for i in vocabulary if not i in stop_words}\n",
    "trend=classifier.classify(featurized_test_sentence)\n",
    "\n",
    "test_sentence_prob= classifier.prob_classify(featurized_test_sentence)\n",
    "\n",
    "test_sentence_prob=100*test_sentence_prob.prob(test_sentence_prob.max())\n",
    "\n",
    "print(\"trend: \"+ trend +\", confidence: {}%\".format(round(test_sentence_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
