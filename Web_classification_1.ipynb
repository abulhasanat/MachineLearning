{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_classification_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/MachineLearning/blob/master/Web_classification_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDSwsdfxbYAk",
        "colab_type": "code",
        "outputId": "a9af09d5-0222-4b6b-f8b5-c2fd725d0935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install JPype1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting JPype1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 3.1MB/s \n",
            "\u001b[?25hInstalling collected packages: JPype1\n",
            "Successfully installed JPype1-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8jTXFwOxwc5",
        "colab_type": "code",
        "outputId": "4d373efe-a453-421f-ea49-3b272cb73b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/misja/python-boilerpipe.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'python-boilerpipe'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "remote: Total 264 (delta 0), reused 0 (delta 0), pack-reused 264\u001b[K\n",
            "Receiving objects:   0% (1/264)   \rReceiving objects:   1% (3/264)   \rReceiving objects:   2% (6/264)   \rReceiving objects:   3% (8/264)   \rReceiving objects:   4% (11/264)   \rReceiving objects:   5% (14/264)   \rReceiving objects:   6% (16/264)   \rReceiving objects:   7% (19/264)   \rReceiving objects:   8% (22/264)   \rReceiving objects:   9% (24/264)   \rReceiving objects:  10% (27/264)   \rReceiving objects:  11% (30/264)   \rReceiving objects:  12% (32/264)   \rReceiving objects:  13% (35/264)   \rReceiving objects:  14% (37/264)   \rReceiving objects:  15% (40/264)   \rReceiving objects:  16% (43/264)   \rReceiving objects:  17% (45/264)   \rReceiving objects:  18% (48/264)   \rReceiving objects:  19% (51/264)   \rReceiving objects:  20% (53/264)   \rReceiving objects:  21% (56/264)   \rReceiving objects:  22% (59/264)   \rReceiving objects:  23% (61/264)   \rReceiving objects:  24% (64/264)   \rReceiving objects:  25% (66/264)   \rReceiving objects:  26% (69/264)   \rReceiving objects:  27% (72/264)   \rReceiving objects:  28% (74/264)   \rReceiving objects:  29% (77/264)   \rReceiving objects:  30% (80/264)   \rReceiving objects:  31% (82/264)   \rReceiving objects:  32% (85/264)   \rReceiving objects:  33% (88/264)   \rReceiving objects:  34% (90/264)   \rReceiving objects:  35% (93/264)   \rReceiving objects:  36% (96/264)   \rReceiving objects:  37% (98/264)   \rReceiving objects:  38% (101/264)   \rReceiving objects:  39% (103/264)   \rReceiving objects:  40% (106/264)   \rReceiving objects:  41% (109/264)   \rReceiving objects:  42% (111/264)   \rReceiving objects:  43% (114/264)   \rReceiving objects:  44% (117/264)   \rReceiving objects:  45% (119/264)   \rReceiving objects:  46% (122/264)   \rReceiving objects:  47% (125/264)   \rReceiving objects:  48% (127/264)   \rReceiving objects:  49% (130/264)   \rReceiving objects:  50% (132/264)   \rReceiving objects:  51% (135/264)   \rReceiving objects:  52% (138/264)   \rReceiving objects:  53% (140/264)   \rReceiving objects:  54% (143/264)   \rReceiving objects:  55% (146/264)   \rReceiving objects:  56% (148/264)   \rReceiving objects:  57% (151/264)   \rReceiving objects:  58% (154/264)   \rReceiving objects:  59% (156/264)   \rReceiving objects:  60% (159/264)   \rReceiving objects:  61% (162/264)   \rReceiving objects:  62% (164/264)   \rReceiving objects:  63% (167/264)   \rReceiving objects:  64% (169/264)   \rReceiving objects:  65% (172/264)   \rReceiving objects:  66% (175/264)   \rReceiving objects:  67% (177/264)   \rReceiving objects:  68% (180/264)   \rReceiving objects:  69% (183/264)   \rReceiving objects:  70% (185/264)   \rReceiving objects:  71% (188/264)   \rReceiving objects:  72% (191/264)   \rReceiving objects:  73% (193/264)   \rReceiving objects:  74% (196/264)   \rReceiving objects:  75% (198/264)   \rReceiving objects:  76% (201/264)   \rReceiving objects:  77% (204/264)   \rReceiving objects:  78% (206/264)   \rReceiving objects:  79% (209/264)   \rReceiving objects:  80% (212/264)   \rReceiving objects:  81% (214/264)   \rReceiving objects:  82% (217/264)   \rReceiving objects:  83% (220/264)   \rReceiving objects:  84% (222/264)   \rReceiving objects:  85% (225/264)   \rReceiving objects:  86% (228/264)   \rReceiving objects:  87% (230/264)   \rReceiving objects:  88% (233/264)   \rReceiving objects:  89% (235/264)   \rReceiving objects:  90% (238/264)   \rReceiving objects:  91% (241/264)   \rReceiving objects:  92% (243/264)   \rReceiving objects:  93% (246/264)   \rReceiving objects:  94% (249/264)   \rReceiving objects:  95% (251/264)   \rReceiving objects:  96% (254/264)   \rReceiving objects:  97% (257/264)   \rReceiving objects:  98% (259/264)   \rReceiving objects:  99% (262/264)   \rReceiving objects: 100% (264/264)   \rReceiving objects: 100% (264/264), 30.28 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas:   0% (0/90)   \rResolving deltas:   1% (1/90)   \rResolving deltas:   4% (4/90)   \rResolving deltas:   7% (7/90)   \rResolving deltas:  10% (9/90)   \rResolving deltas:  14% (13/90)   \rResolving deltas:  17% (16/90)   \rResolving deltas:  22% (20/90)   \rResolving deltas:  33% (30/90)   \rResolving deltas:  35% (32/90)   \rResolving deltas:  37% (34/90)   \rResolving deltas:  38% (35/90)   \rResolving deltas:  44% (40/90)   \rResolving deltas:  47% (43/90)   \rResolving deltas:  48% (44/90)   \rResolving deltas:  51% (46/90)   \rResolving deltas:  52% (47/90)   \rResolving deltas:  56% (51/90)   \rResolving deltas:  57% (52/90)   \rResolving deltas:  58% (53/90)   \rResolving deltas:  60% (54/90)   \rResolving deltas:  61% (55/90)   \rResolving deltas:  62% (56/90)   \rResolving deltas:  63% (57/90)   \rResolving deltas:  65% (59/90)   \rResolving deltas:  66% (60/90)   \rResolving deltas:  67% (61/90)   \rResolving deltas:  68% (62/90)   \rResolving deltas: 100% (90/90)   \rResolving deltas: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g6iCiGSTJBB",
        "colab_type": "code",
        "outputId": "d1fbbff1-6484-46fa-d56c-676c4267aa70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "%cd /content/python-boilerpipe\n",
        "!sudo python setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/python-boilerpipe\n",
            "/usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'install_requires'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/boilerpipe\n",
            "copying src/boilerpipe/__init__.py -> build/lib/boilerpipe\n",
            "creating build/lib/boilerpipe/extract\n",
            "copying src/boilerpipe/extract/__init__.py -> build/lib/boilerpipe/extract\n",
            "creating build/lib/boilerpipe/data\n",
            "creating build/lib/boilerpipe/data/boilerpipe-1.2.0\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/boilerpipe-1.2.0.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0\n",
            "creating build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/lib/xerces-2.9.1.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/lib/nekohtml-1.9.13.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/extract\n",
            "copying build/lib/boilerpipe/extract/__init__.py -> /usr/local/lib/python3.6/dist-packages/boilerpipe/extract\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/boilerpipe-1.2.0.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/lib/xerces-2.9.1.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/lib/nekohtml-1.9.13.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/__init__.py -> /usr/local/lib/python3.6/dist-packages/boilerpipe\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/boilerpipe/extract/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/boilerpipe/__init__.py to __init__.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/boilerpipe-1.3.0.0.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fenv3zFDML7",
        "colab_type": "code",
        "outputId": "3373310f-3428-4f9a-fd32-297c3ba96d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDvDWgwXaqmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5vHDl_nbDgH",
        "colab_type": "code",
        "outputId": "f38cd194-8b43-47be-9651-941cee1987d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import requests\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "\n",
        "import random\n",
        "import math\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "import collections\n",
        "from boilerpipe.extract import Extractor"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jpype/_core.py:210: UserWarning: \n",
            "-------------------------------------------------------------------------------\n",
            "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
            "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
            "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
            "this session. If you are a user of an application that reported this warning,\n",
            "please file a ticket with the developer.\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJwkjiTCcvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzARg0qRChsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkKwZ9T2Ckso",
        "colab_type": "code",
        "outputId": "b29a3ebd-4189-4d41-a5e6-fb98ea25ee33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "%%bash\n",
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.36)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Collecting regex\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.36)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py): started\n",
            "  Building wheel for regex (setup.py): finished with status 'done'\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609182 sha256=9e3fcb95f580c54c606f50f5e1c59dc5440e0187da552941bef8dc224fdb75a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2EvjxeiaBUF",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    testing=True,\n",
        "    bert_model_name=\"bert-base-uncased\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=4,\n",
        "    use_fp16=False,\n",
        "    bs=32,\n",
        "    discriminative=False,\n",
        "    max_seq_len=256,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBfco7WHC0Wv",
        "colab_type": "code",
        "outputId": "2379b9fe-b46c-47dc-af8a-cb243cc7b6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "bert_tok = BertTokenizer.from_pretrained(\n",
        "    config.bert_model_name,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5897162.18B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_Cg9soDFS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _join_texts(texts:Collection[str], mark_fields:bool=False, sos_token:Optional[str]=BOS):\n",
        "    \"\"\"Borrowed from fast.ai source\"\"\"\n",
        "    if not isinstance(texts, np.ndarray): texts = np.array(texts)\n",
        "    if is1d(texts): texts = texts[:,None]\n",
        "    df = pd.DataFrame({i:texts[:,i] for i in range(texts.shape[1])})\n",
        "    text_col = f'{FLD} {1} ' + df[0].astype(str) if mark_fields else df[0].astype(str)\n",
        "    if sos_token is not None: text_col = f\"{sos_token} \" + text_col\n",
        "    for i in range(1,len(df.columns)):\n",
        "        #text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i]\n",
        "        text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i].astype(str)\n",
        "    return text_col.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts9ljYXiDKEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0VN9Sa6D-_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for BERT\n",
        "    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original BERT model.\n",
        "    \"\"\"\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),NumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mCEG5bi1fRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUA():\n",
        "    uastrings = [\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.72 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\"\\\n",
        "                ]\n",
        "\n",
        "    return random.choice(uastrings)\n",
        "\n",
        "def prepare_sentences(text):\n",
        "    text=text.replace('\\n',' ')\n",
        "    # Clean characters\n",
        "    text = \"\".join([t for t in text if t.isalnum() or t in string.punctuation or t == ' '])\n",
        "    \n",
        "    # Get rid of whitespace characters\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    text = \" \".join([s.strip() for s in sentences])\n",
        "    \n",
        "    # Fix puctuation spacing\n",
        "    text = re.sub(r\"(\\w{2,})([\\.\\!\\?]+)(\\w)\", r\"\\1\\2 \\3\", text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n",
        "\n",
        "def find_children(n1, n2):\n",
        "    \n",
        "    children1 = [c for c in n1.children]\n",
        "    children2 = [c for c in n2.children]\n",
        "    \n",
        "    for i, children in enumerate([children1,children2]):\n",
        "        level = 1\n",
        "\n",
        "        while children:\n",
        "            lchildren = children\n",
        "            children = []\n",
        "            for ch in lchildren:\n",
        "                if not ch.name:\n",
        "                    continue\n",
        "                if ch == n1 or ch == n2:\n",
        "                    if i == 0:\n",
        "                        return len( nltk.sent_tokenize(n2.get_text()) ) * ( 1/math.exp(level) )\n",
        "                    else:\n",
        "                        return len( nltk.sent_tokenize(n1.get_text()) ) * ( 1/math.exp(level) )\n",
        "                                        \n",
        "                children.extend(ch.children)\n",
        "\n",
        "            level += 1\n",
        "            \n",
        "    return 0\n",
        "\n",
        "def extract_html(url, timeout=10):\n",
        "    headers = {'user-agent': getUA()}\n",
        "    r = requests.get(url, headers = headers, verify=False, timeout=timeout)\n",
        "    html = r.content\n",
        "    return html\n",
        "\n",
        "def tokenize_url(url:str):   \n",
        "    url=re.sub(\"(\\W|_)+\",\" \",url)\n",
        "    return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHAqwTr1Jr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZwZFQ3T1qBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_title(soup):\n",
        "    try:\n",
        "        for i in list(soup.find_all('title')):\n",
        "            return(i.get_text().replace(\"\\n\",\" \").replace(\"\\t\",\" \").strip())\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def list2string(x):\n",
        "    s=\"\"\n",
        "    try:\n",
        "        for i in x:\n",
        "            for j in i:\n",
        "                if j!=None:\n",
        "                    s = s + j+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return (s)\n",
        "\n",
        "def get_metadata_property(soup):\n",
        "    try:\n",
        "        x=[i.get('property') for i in soup.findAll('meta')]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "        z=np.c_[x,v]\n",
        "        return list2string(z)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_metadata_name(soup):\n",
        "    try:\n",
        "        y=[i.get('name') for i in soup.findAll('meta')]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "        z=np.c_[y,v]\n",
        "        return list2string(z)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_metadata_content(soup):\n",
        "    try:\n",
        "        v=[]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "    #     return list2string(v)\n",
        "        return (v)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_text(soup):\n",
        "    text=\"\"\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            text+=item.get_text()+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return text\n",
        "#     return (len(text.split())/COUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s9-_I0V1wnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_count(soup):\n",
        "    text=\"\"\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            text+=item.get_text()+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return len(text.split())\n",
        "\n",
        "def get_para_count(soup):\n",
        "    count=0\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            count+=1\n",
        "    except:\n",
        "        pass\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtSpyUhG10U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_internal_links(url_main,links):\n",
        "    internal_url_list=[]\n",
        "    try:\n",
        "        for item in links:\n",
        "            for url_parts in url_main.split('.')[:-1]:\n",
        "                if (url_parts in item.lower()):\n",
        "                    internal_url_list.append(item)\n",
        "        internal_url_list=list(dict.fromkeys(internal_url_list))    \n",
        "        return(len(internal_url_list))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_external_links(url_main,links):\n",
        "    external_url_list=[]\n",
        "    try:\n",
        "        for item in links:\n",
        "            count=0\n",
        "            for url_parts in url_main.split('.')[:-1]:\n",
        "                if (item.startswith(('http', 'ftp', 'www')) and (url_parts not in item.lower())):\n",
        "                    count+=1\n",
        "            if count==len(url_main.split('.')[:-1]):\n",
        "                external_url_list.append(item)\n",
        "        return(len(external_url_list))\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noWAhteO14Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(url):\n",
        "    # create a new Chrome session\n",
        "    try:\n",
        "        print(url)\n",
        "        metadata_property=''\n",
        "        metadata_name=''\n",
        "        metadata_content=''\n",
        "        title=''\n",
        "        word_count=0\n",
        "        sen_count=0\n",
        "        internal_links=0\n",
        "        external_links=0\n",
        "    #         driver = webdriver.Chrome(executable_path=r'D:/chromedriver_win32/chromedriver.exe')\n",
        "    #         driver.set_page_load_timeout(60)\n",
        "    #         driver.get(url)\n",
        "    #         html = driver.page_source\n",
        "    #         driver.close()\n",
        "    #         soup = BeautifulSoup(html, 'html.parser')  #Parse html code       \n",
        "    #         body = soup.find('body')\n",
        "\n",
        "        html= extract_html(url, 100)\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "        body = soup.find('body')\n",
        "        remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "                                             \"svg\", \"h1\",\"h2\", \"h3\", \"h4\", \"h5\", \"xml\"])]\n",
        "        text = \"\"\n",
        "        boilerpipe_sentences=\"\"\n",
        "        boilerpipe_content = prepare_sentences(Extractor(extractor='CanolaExtractor', html=html).getText())\n",
        "        boilerpipe_sentences = prepare_sentences(boilerpipe_content)\n",
        "    #         print('Sentences:',len(boilerpipe_sentences))\n",
        "\n",
        "#         p = '(?:http.*://)?(?:www.)?(?P<host>[^/ ]+).?(?P<port>[0-9]*).*'\n",
        "        p = '(?:http.*://)?(?:www[0-9].|www.)?(?P<host>[^/ ]+).?(?P<port>[0-9]*).*'\n",
        "        m = re.search(p,url)\n",
        "        url_main = m.group('host') # 'www.abc.com'\n",
        "        if len(soup)>0:\n",
        "            metadata_property=get_metadata_property(soup)\n",
        "            metadata_name=get_metadata_name(soup)\n",
        "            metadata_content=get_metadata_content(soup)\n",
        "            title=get_title(soup)\n",
        "            \n",
        "            word_count=len(nltk.word_tokenize(boilerpipe_sentences))\n",
        "            \n",
        "            sen_count=len(nltk.sent_tokenize(boilerpipe_sentences))       \n",
        "\n",
        "            links = [ x['href'] for x in soup.find_all('a', href=True) ]\n",
        "            if len(links)>0:\n",
        "                internal_links=get_internal_links(url_main,links)\n",
        "                external_links=get_external_links(url_main,links)\n",
        "\n",
        "    #         return pd.Series([get_metadata_property(soup),get_metadata_name(soup),get_metadata_content(soup),\n",
        "    #                       get_title(soup)])\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    extract= pd.Series([metadata_property,metadata_name,metadata_content,\n",
        "                          title,word_count,sen_count,internal_links,external_links])\n",
        "    #         extract= pd.Series([get_metadata_property(soup),get_metadata_name(soup)])\n",
        "    return extract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nURhD1_6Fsph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test=pd.DataFrame(pd.Series([boilerpipe_sentences,0,0,0,0,0,0]),columns=['category','label_1',\t'label_3',\t'label_5',\t'label_6',\t'label_7',\t'label_8'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KvuYhtOuXHym",
        "colab": {}
      },
      "source": [
        "# label_cols=['label_1',\t'label_3',\t'label_5',\t'label_6',\t'label_7',\t'label_8']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZHDV1SeX2_L",
        "colab_type": "code",
        "outputId": "13d0577a-54a7-4bbb-b9ed-1ecbbc75bc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "DATA_ROOT=Path('/content/drive/My Drive/Data/DMOZ')\n",
        "# learner.load(file=DATA_ROOT/'Model_DMOZ(6_cat).pkl')\n",
        "learn = load_learner(DATA_ROOT, 'Model_DMOZ(6_cat).pkl')\n",
        "# learn = load_learner(DATA_ROOT, 'Model_DMOZ(25_cat).pkl')\n",
        "# learn = load_learner(DATA_ROOT, 'Model_DMOZ(all_cat_v1_2).pkl')\n",
        "learn.to_fp32()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Learner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (0 items)\n",
              "x: TextList\n",
              "\n",
              "y: MultiCategoryList\n",
              "\n",
              "Path: /content/drive/My Drive/Data/DMOZ;\n",
              "\n",
              "Valid: LabelList (0 items)\n",
              "x: TextList\n",
              "\n",
              "y: MultiCategoryList\n",
              "\n",
              "Path: /content/drive/My Drive/Data/DMOZ;\n",
              "\n",
              "Test: None, model=BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=BCEWithLogitsLoss(), metrics=[], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/content/drive/My Drive/Data/DMOZ'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[], layer_groups=[Sequential(\n",
              "  (0): Embedding(30522, 768, padding_idx=0)\n",
              "  (1): Embedding(512, 768)\n",
              "  (2): Embedding(2, 768)\n",
              "  (3): BertLayerNorm()\n",
              "  (4): Dropout(p=0.1, inplace=False)\n",
              "  (5): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (6): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (7): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (8): Dropout(p=0.1, inplace=False)\n",
              "  (9): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (10): BertLayerNorm()\n",
              "  (11): Dropout(p=0.1, inplace=False)\n",
              "  (12): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (13): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (14): BertLayerNorm()\n",
              "  (15): Dropout(p=0.1, inplace=False)\n",
              "  (16): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (17): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (18): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (19): Dropout(p=0.1, inplace=False)\n",
              "  (20): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (21): BertLayerNorm()\n",
              "  (22): Dropout(p=0.1, inplace=False)\n",
              "  (23): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (24): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (25): BertLayerNorm()\n",
              "  (26): Dropout(p=0.1, inplace=False)\n",
              "  (27): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (28): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (29): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (30): Dropout(p=0.1, inplace=False)\n",
              "  (31): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (32): BertLayerNorm()\n",
              "  (33): Dropout(p=0.1, inplace=False)\n",
              "  (34): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (35): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (36): BertLayerNorm()\n",
              "  (37): Dropout(p=0.1, inplace=False)\n",
              "  (38): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (39): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (40): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (41): Dropout(p=0.1, inplace=False)\n",
              "  (42): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (43): BertLayerNorm()\n",
              "  (44): Dropout(p=0.1, inplace=False)\n",
              "  (45): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (46): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (47): BertLayerNorm()\n",
              "  (48): Dropout(p=0.1, inplace=False)\n",
              "  (49): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (50): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (51): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (52): Dropout(p=0.1, inplace=False)\n",
              "  (53): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (54): BertLayerNorm()\n",
              "  (55): Dropout(p=0.1, inplace=False)\n",
              "  (56): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (57): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (58): BertLayerNorm()\n",
              "  (59): Dropout(p=0.1, inplace=False)\n",
              "  (60): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (61): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (62): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (63): Dropout(p=0.1, inplace=False)\n",
              "  (64): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (65): BertLayerNorm()\n",
              "  (66): Dropout(p=0.1, inplace=False)\n",
              "  (67): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (68): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (69): BertLayerNorm()\n",
              "  (70): Dropout(p=0.1, inplace=False)\n",
              "  (71): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (72): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (73): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (74): Dropout(p=0.1, inplace=False)\n",
              "  (75): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (76): BertLayerNorm()\n",
              "  (77): Dropout(p=0.1, inplace=False)\n",
              "  (78): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (79): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (80): BertLayerNorm()\n",
              "  (81): Dropout(p=0.1, inplace=False)\n",
              "  (82): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (83): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (84): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (85): Dropout(p=0.1, inplace=False)\n",
              "  (86): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (87): BertLayerNorm()\n",
              "  (88): Dropout(p=0.1, inplace=False)\n",
              "  (89): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (90): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (91): BertLayerNorm()\n",
              "  (92): Dropout(p=0.1, inplace=False)\n",
              "  (93): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (94): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (95): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (96): Dropout(p=0.1, inplace=False)\n",
              "  (97): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (98): BertLayerNorm()\n",
              "  (99): Dropout(p=0.1, inplace=False)\n",
              "  (100): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (101): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (102): BertLayerNorm()\n",
              "  (103): Dropout(p=0.1, inplace=False)\n",
              "  (104): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (105): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (106): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (107): Dropout(p=0.1, inplace=False)\n",
              "  (108): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (109): BertLayerNorm()\n",
              "  (110): Dropout(p=0.1, inplace=False)\n",
              "  (111): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (112): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (113): BertLayerNorm()\n",
              "  (114): Dropout(p=0.1, inplace=False)\n",
              "  (115): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (116): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (117): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (118): Dropout(p=0.1, inplace=False)\n",
              "  (119): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (120): BertLayerNorm()\n",
              "  (121): Dropout(p=0.1, inplace=False)\n",
              "  (122): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (123): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (124): BertLayerNorm()\n",
              "  (125): Dropout(p=0.1, inplace=False)\n",
              "  (126): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (127): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (128): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (129): Dropout(p=0.1, inplace=False)\n",
              "  (130): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (131): BertLayerNorm()\n",
              "  (132): Dropout(p=0.1, inplace=False)\n",
              "  (133): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  (134): Linear(in_features=3072, out_features=768, bias=True)\n",
              "  (135): BertLayerNorm()\n",
              "  (136): Dropout(p=0.1, inplace=False)\n",
              "  (137): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (138): Tanh()\n",
              "  (139): Dropout(p=0.1, inplace=False)\n",
              "  (140): Linear(in_features=768, out_features=6, bias=True)\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eji8RpszXGgJ",
        "outputId": "28ee2b40-e4d7-407a-a8bd-5f06519700f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "url='https://docs.fast.ai/text.html'\n",
        "html= extract_html(url, 60)\n",
        "soup = BeautifulSoup(html, 'lxml')\n",
        "body = soup.find('body')\n",
        "# remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "#                                      \"svg\", \"h1\",\"h2\", \"h3\", \"h4\", \"h5\", \"xml\"])]\n",
        "remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "                                     \"svg\", \"xml\"])]\n",
        "boilerpipe_content = prepare_sentences(Extractor(extractor='CanolaExtractor', html=html).getText())\n",
        "boilerpipe_sentences = prepare_sentences(boilerpipe_content)\n",
        "print(boilerpipe_sentences)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The text module of the fastai library contains all the necessary functions to define a Dataset suitable for the various NLP (Natural Language Processing) tasks and quickly generate models you can use for them. Specifically: text. transform contains all the scripts to preprocess your data, from raw text to token ids, text. data contains the definition of TextDataBunch , which the main class you'll need in NLP, text. learner contains helper functions to quickly create a language model or an RNN classifier. Have a look at the links above for full details of the API of each module, of read on for a quick overview. Quick Start: Training an IMDb sentiment model with ULMFiT Let's start with a quick end-to-end example of training a model. We'll train a sentiment classifier on a sample of the popular IMDb data, showing 4 steps: from fastai. text import * Contrary to images in Computer Vision, text can't directly be transformed into numbers to be fed into a model. The first thing we need to do is to preprocess our data so that we change the raw texts to lists of words, or tokens (a step that is called tokenization) then transform these tokens into numbers (a step that is called numericalization). These numbers are then passed to embedding layers that will convert them in arrays of floats before passing them through a model. You can find on the web plenty of Word Embeddings to directly convert your tokens into floats. Those word embeddings have generally be trained on a large corpus such as wikipedia. Following the work of ULMFiT , the fastai library is more focused on using pre-trained Language Models and fine-tuning them. Word embeddings are just vectors of 300 or 400 floats that represent different words, but a pretrained language model not only has those, but has also been trained to get a representation of full sentences and documents. Get your data preprocessed and ready to use in a minimum amount of code, Create a language model with pretrained weights that you can fine-tune to your dataset, To show examples, we have provided a small sample of the IMDB dataset which contains 1,000 reviews of movies with labels (positive or negative). Creating a dataset from your raw texts is very simple if you have it in one of those ways organized it in folders in an ImageNet style organized in a csv file with labels columns and a text columns To get a DataBunch quickly, there are also several factory methods depending on how our data is structured. They are all detailed in text. data , here we'll use the method from_csv of the TextLMDataBunch (to get the data ready for a language model) and TextClasDataBunch (to get the data ready for a text classifier) classes. This does all the necessary preprocessing behind the scene. For the classifier, we also pass the vocabulary (mapping from ids to words) that we want to use: this is to ensure that data_clas will use the same dictionary as data_lm. data_lm. save('data_lm_export. pkl') data_clas. save('data_clas_export. pkl') This will create a 'tmp' directory where all the computed stuff will be stored. You can then reload those results with: We can use the data_lm object we created earlier to fine-tune a pretrained language model. fast. ai has an English model with an AWD-LSTM architecture available that we can download. We can create a learner object that will directly create a model, download the pretrained weights and be ready for fine-tuning. To evaluate your language model, you can run the Learner. predict method and specify the number of words you want it to guess. 'This is a review about what was worth a word of reading , where some' It doesn't make much sense (we have a tiny vocabulary here and didn't train much on it) but note that it respects basic grammar (which comes from the pretrained model). Building a classifier We now use the data_clas object we created earlier to build a classifier with our fine-tuned encoder. The learner object can be done in a single line. target xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , steaming bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj negative xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with positive xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj sydney , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n xxmaj it 's usually satisfying to watch a film director change his style / negative xxbos xxmaj this film sat on my xxmaj tivo for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj yorkers . \\n \\n xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde positive xxbos i really wanted to love this show . i truly , honestly did . \\n \\n xxmaj for the first time , gay viewers get their own version of the \" xxmaj the xxmaj bachelor \" . xxmaj with the help of his obligatory \" hag \" xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMIQbNBMYn-0",
        "colab_type": "code",
        "outputId": "d3a4260e-31d2-468b-8a61-869a40dc2c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "learn.predict(boilerpipe_sentences)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MultiCategory label_5,\n",
              " tensor([0., 0., 1., 0., 0., 0.]),\n",
              " tensor([0.0609, 0.1144, 0.8853, 0.0432, 0.0450, 0.0558]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hYQ6wlZZNyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}