{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_classification_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/MachineLearning/blob/master/Web_classification_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDSwsdfxbYAk",
        "colab_type": "code",
        "outputId": "a7b4e7a3-e81a-4523-c9e2-1d893d6a46a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install JPype1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting JPype1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: JPype1\n",
            "Successfully installed JPype1-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8jTXFwOxwc5",
        "colab_type": "code",
        "outputId": "05dd14cc-85d5-4e17-b0c2-d8b74a13b3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/misja/python-boilerpipe.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'python-boilerpipe'...\n",
            "remote: Enumerating objects: 264, done.\u001b[K\n",
            "Receiving objects:   0% (1/264)   \rReceiving objects:   1% (3/264)   \rReceiving objects:   2% (6/264)   \rReceiving objects:   3% (8/264)   \rReceiving objects:   4% (11/264)   \rReceiving objects:   5% (14/264)   \rReceiving objects:   6% (16/264)   \rReceiving objects:   7% (19/264)   \rReceiving objects:   8% (22/264)   \rReceiving objects:   9% (24/264)   \rReceiving objects:  10% (27/264)   \rReceiving objects:  11% (30/264)   \rReceiving objects:  12% (32/264)   \rReceiving objects:  13% (35/264)   \rReceiving objects:  14% (37/264)   \rReceiving objects:  15% (40/264)   \rReceiving objects:  16% (43/264)   \rReceiving objects:  17% (45/264)   \rReceiving objects:  18% (48/264)   \rReceiving objects:  19% (51/264)   \rReceiving objects:  20% (53/264)   \rReceiving objects:  21% (56/264)   \rReceiving objects:  22% (59/264)   \rReceiving objects:  23% (61/264)   \rReceiving objects:  24% (64/264)   \rReceiving objects:  25% (66/264)   \rReceiving objects:  26% (69/264)   \rReceiving objects:  27% (72/264)   \rReceiving objects:  28% (74/264)   \rReceiving objects:  29% (77/264)   \rReceiving objects:  30% (80/264)   \rReceiving objects:  31% (82/264)   \rReceiving objects:  32% (85/264)   \rReceiving objects:  33% (88/264)   \rReceiving objects:  34% (90/264)   \rReceiving objects:  35% (93/264)   \rReceiving objects:  36% (96/264)   \rReceiving objects:  37% (98/264)   \rReceiving objects:  38% (101/264)   \rReceiving objects:  39% (103/264)   \rReceiving objects:  40% (106/264)   \rReceiving objects:  41% (109/264)   \rReceiving objects:  42% (111/264)   \rReceiving objects:  43% (114/264)   \rReceiving objects:  44% (117/264)   \rReceiving objects:  45% (119/264)   \rReceiving objects:  46% (122/264)   \rReceiving objects:  47% (125/264)   \rReceiving objects:  48% (127/264)   \rReceiving objects:  49% (130/264)   \rReceiving objects:  50% (132/264)   \rReceiving objects:  51% (135/264)   \rReceiving objects:  52% (138/264)   \rReceiving objects:  53% (140/264)   \rReceiving objects:  54% (143/264)   \rReceiving objects:  55% (146/264)   \rReceiving objects:  56% (148/264)   \rReceiving objects:  57% (151/264)   \rReceiving objects:  58% (154/264)   \rReceiving objects:  59% (156/264)   \rReceiving objects:  60% (159/264)   \rReceiving objects:  61% (162/264)   \rReceiving objects:  62% (164/264)   \rReceiving objects:  63% (167/264)   \rReceiving objects:  64% (169/264)   \rremote: Total 264 (delta 0), reused 0 (delta 0), pack-reused 264\u001b[K\n",
            "Receiving objects:  65% (172/264)   \rReceiving objects:  66% (175/264)   \rReceiving objects:  67% (177/264)   \rReceiving objects:  68% (180/264)   \rReceiving objects:  69% (183/264)   \rReceiving objects:  70% (185/264)   \rReceiving objects:  71% (188/264)   \rReceiving objects:  72% (191/264)   \rReceiving objects:  73% (193/264)   \rReceiving objects:  74% (196/264)   \rReceiving objects:  75% (198/264)   \rReceiving objects:  76% (201/264)   \rReceiving objects:  77% (204/264)   \rReceiving objects:  78% (206/264)   \rReceiving objects:  79% (209/264)   \rReceiving objects:  80% (212/264)   \rReceiving objects:  81% (214/264)   \rReceiving objects:  82% (217/264)   \rReceiving objects:  83% (220/264)   \rReceiving objects:  84% (222/264)   \rReceiving objects:  85% (225/264)   \rReceiving objects:  86% (228/264)   \rReceiving objects:  87% (230/264)   \rReceiving objects:  88% (233/264)   \rReceiving objects:  89% (235/264)   \rReceiving objects:  90% (238/264)   \rReceiving objects:  91% (241/264)   \rReceiving objects:  92% (243/264)   \rReceiving objects:  93% (246/264)   \rReceiving objects:  94% (249/264)   \rReceiving objects:  95% (251/264)   \rReceiving objects:  96% (254/264)   \rReceiving objects:  97% (257/264)   \rReceiving objects:  98% (259/264)   \rReceiving objects:  99% (262/264)   \rReceiving objects: 100% (264/264)   \rReceiving objects: 100% (264/264), 30.28 KiB | 3.78 MiB/s, done.\n",
            "Resolving deltas:   0% (0/90)   \rResolving deltas:   1% (1/90)   \rResolving deltas:   5% (5/90)   \rResolving deltas:   6% (6/90)   \rResolving deltas:  13% (12/90)   \rResolving deltas:  16% (15/90)   \rResolving deltas:  31% (28/90)   \rResolving deltas:  32% (29/90)   \rResolving deltas:  36% (33/90)   \rResolving deltas:  38% (35/90)   \rResolving deltas:  44% (40/90)   \rResolving deltas:  46% (42/90)   \rResolving deltas:  48% (44/90)   \rResolving deltas:  55% (50/90)   \rResolving deltas:  57% (52/90)   \rResolving deltas:  58% (53/90)   \rResolving deltas:  61% (55/90)   \rResolving deltas:  63% (57/90)   \rResolving deltas:  66% (60/90)   \rResolving deltas:  67% (61/90)   \rResolving deltas:  68% (62/90)   \rResolving deltas:  71% (64/90)   \rResolving deltas:  72% (65/90)   \rResolving deltas:  74% (67/90)   \rResolving deltas:  76% (69/90)   \rResolving deltas:  78% (71/90)   \rResolving deltas:  80% (72/90)   \rResolving deltas:  81% (73/90)   \rResolving deltas: 100% (90/90)   \rResolving deltas: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g6iCiGSTJBB",
        "colab_type": "code",
        "outputId": "5aa68c18-e76b-41d1-86a0-687c8f7df184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%cd /content/python-boilerpipe\n",
        "!sudo python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/python-boilerpipe\n",
            "/usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'install_requires'\n",
            "  warnings.warn(msg)\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/boilerpipe\n",
            "copying src/boilerpipe/__init__.py -> build/lib/boilerpipe\n",
            "creating build/lib/boilerpipe/extract\n",
            "copying src/boilerpipe/extract/__init__.py -> build/lib/boilerpipe/extract\n",
            "creating build/lib/boilerpipe/data\n",
            "creating build/lib/boilerpipe/data/boilerpipe-1.2.0\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/boilerpipe-1.2.0.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0\n",
            "creating build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/lib/xerces-2.9.1.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying src/boilerpipe/data/boilerpipe-1.2.0/lib/nekohtml-1.9.13.jar -> build/lib/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/extract\n",
            "copying build/lib/boilerpipe/extract/__init__.py -> /usr/local/lib/python3.6/dist-packages/boilerpipe/extract\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/boilerpipe-1.2.0.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0\n",
            "creating /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/lib/xerces-2.9.1.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/data/boilerpipe-1.2.0/lib/nekohtml-1.9.13.jar -> /usr/local/lib/python3.6/dist-packages/boilerpipe/data/boilerpipe-1.2.0/lib\n",
            "copying build/lib/boilerpipe/__init__.py -> /usr/local/lib/python3.6/dist-packages/boilerpipe\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/boilerpipe/extract/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/boilerpipe/__init__.py to __init__.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Writing /usr/local/lib/python3.6/dist-packages/boilerpipe-1.3.0.0.egg-info\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDvDWgwXaqmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5vHDl_nbDgH",
        "colab_type": "code",
        "outputId": "57ae432e-560c-48fb-f271-3d9d347ba51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import requests\n",
        "requests.packages.urllib3.disable_warnings()\n",
        "\n",
        "import random\n",
        "import math\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "import collections\n",
        "from boilerpipe.extract import Extractor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jpype/_core.py:210: UserWarning: \n",
            "-------------------------------------------------------------------------------\n",
            "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
            "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
            "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
            "this session. If you are a user of an application that reported this warning,\n",
            "please file a ticket with the developer.\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJwkjiTCcvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzARg0qRChsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkKwZ9T2Ckso",
        "colab_type": "code",
        "outputId": "38e6517f-96b9-45ed-cafb-5b48fd46c421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "%%bash\n",
        "pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "Collecting regex\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/db/4b29a0adec5881542cd81cb5d1929b5c0787003c5740b3c921e627d9c2e5/regex-2019.12.9.tar.gz (669kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.36)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.36->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py): started\n",
            "  Building wheel for regex (setup.py): finished with status 'done'\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609182 sha256=b33783e16aba1cd4763a78b280381417a9e537125cfe531062efb0281bd7d13a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A2EvjxeiaBUF",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "\n",
        "config = Config(\n",
        "    testing=True,\n",
        "    bert_model_name=\"bert-base-uncased\",\n",
        "    max_lr=3e-5,\n",
        "    epochs=4,\n",
        "    use_fp16=True,\n",
        "    bs=32,\n",
        "    discriminative=False,\n",
        "    max_seq_len=256,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBfco7WHC0Wv",
        "colab_type": "code",
        "outputId": "2d5b3f84-d142-4213-f3de-e4fafba5fe59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "bert_tok = BertTokenizer.from_pretrained(\n",
        "    config.bert_model_name,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 6423798.32B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_Cg9soDFS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _join_texts(texts:Collection[str], mark_fields:bool=False, sos_token:Optional[str]=BOS):\n",
        "    \"\"\"Borrowed from fast.ai source\"\"\"\n",
        "    if not isinstance(texts, np.ndarray): texts = np.array(texts)\n",
        "    if is1d(texts): texts = texts[:,None]\n",
        "    df = pd.DataFrame({i:texts[:,i] for i in range(texts.shape[1])})\n",
        "    text_col = f'{FLD} {1} ' + df[0].astype(str) if mark_fields else df[0].astype(str)\n",
        "    if sos_token is not None: text_col = f\"{sos_token} \" + text_col\n",
        "    for i in range(1,len(df.columns)):\n",
        "        #text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i]\n",
        "        text_col += (f' {FLD} {i+1} ' if mark_fields else ' ') + df[i].astype(str)\n",
        "    return text_col.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts9ljYXiDKEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastAiBertTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
        "        self._pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length\"\"\"\n",
        "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fenv3zFDML7",
        "colab_type": "code",
        "outputId": "101e741b-4d02-4f1f-b6ed-96d9113f8782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0VN9Sa6D-_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTokenizeProcessor(TokenizeProcessor):\n",
        "    def __init__(self, tokenizer):\n",
        "        super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "class BertNumericalizeProcessor(NumericalizeProcessor):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, vocab=Vocab(list(bert_tok.vocab.keys())), **kwargs)\n",
        "\n",
        "def get_bert_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):\n",
        "    \"\"\"\n",
        "    Constructing preprocessors for BERT\n",
        "    We remove sos/eos tokens since we add that ourselves in the tokenizer.\n",
        "    We also use a custom vocabulary to match the numericalization with the original BERT model.\n",
        "    \"\"\"\n",
        "    return [BertTokenizeProcessor(tokenizer=tokenizer),NumericalizeProcessor(vocab=vocab)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmdvwUtPEKs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataBunch(TextDataBunch):\n",
        "    @classmethod\n",
        "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
        "                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
        "                label_cols:IntsOrStrs=0, label_delim:str=None, **kwargs) -> DataBunch:\n",
        "        \"Create a `TextDataBunch` from DataFrames.\"\n",
        "        p_kwargs, kwargs = split_kwargs_by_func(kwargs, get_bert_processor)\n",
        "        # use our custom processors while taking tokenizer and vocab as kwargs\n",
        "        processor = get_bert_processor(tokenizer=tokenizer, vocab=vocab, **p_kwargs)\n",
        "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
        "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
        "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
        "        src = src.label_for_lm() if cls==TextLMDataBunch else src.label_from_df(cols=label_cols, classes=classes)\n",
        "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
        "        return src.databunch(**kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBzeMg4jEPXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mCEG5bi1fRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getUA():\n",
        "    uastrings = [\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.72 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
        "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
        "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\"\\\n",
        "                ]\n",
        "\n",
        "    return random.choice(uastrings)\n",
        "\n",
        "def prepare_sentences(text):\n",
        "    text=text.replace('\\n',' ')\n",
        "    # Clean characters\n",
        "    text = \"\".join([t for t in text if t.isalnum() or t in string.punctuation or t == ' '])\n",
        "    \n",
        "    # Get rid of whitespace characters\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    text = \" \".join([s.strip() for s in sentences])\n",
        "    \n",
        "    # Fix puctuation spacing\n",
        "    text = re.sub(r\"(\\w{2,})([\\.\\!\\?]+)(\\w)\", r\"\\1\\2 \\3\", text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n",
        "\n",
        "def find_children(n1, n2):\n",
        "    \n",
        "    children1 = [c for c in n1.children]\n",
        "    children2 = [c for c in n2.children]\n",
        "    \n",
        "    for i, children in enumerate([children1,children2]):\n",
        "        level = 1\n",
        "\n",
        "        while children:\n",
        "            lchildren = children\n",
        "            children = []\n",
        "            for ch in lchildren:\n",
        "                if not ch.name:\n",
        "                    continue\n",
        "                if ch == n1 or ch == n2:\n",
        "                    if i == 0:\n",
        "                        return len( nltk.sent_tokenize(n2.get_text()) ) * ( 1/math.exp(level) )\n",
        "                    else:\n",
        "                        return len( nltk.sent_tokenize(n1.get_text()) ) * ( 1/math.exp(level) )\n",
        "                                        \n",
        "                children.extend(ch.children)\n",
        "\n",
        "            level += 1\n",
        "            \n",
        "    return 0\n",
        "\n",
        "def extract_html(url, timeout=10):\n",
        "    headers = {'user-agent': getUA()}\n",
        "    r = requests.get(url, headers = headers, verify=False, timeout=timeout)\n",
        "    html = r.content\n",
        "    return html\n",
        "\n",
        "def tokenize_url(url:str):   \n",
        "    url=re.sub(\"(\\W|_)+\",\" \",url)\n",
        "    return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHAqwTr1Jr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZwZFQ3T1qBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_title(soup):\n",
        "    try:\n",
        "        for i in list(soup.find_all('title')):\n",
        "            return(i.get_text().replace(\"\\n\",\" \").replace(\"\\t\",\" \").strip())\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def list2string(x):\n",
        "    s=\"\"\n",
        "    try:\n",
        "        for i in x:\n",
        "            for j in i:\n",
        "                if j!=None:\n",
        "                    s = s + j+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return (s)\n",
        "\n",
        "def get_metadata_property(soup):\n",
        "    try:\n",
        "        x=[i.get('property') for i in soup.findAll('meta')]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "        z=np.c_[x,v]\n",
        "        return list2string(z)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_metadata_name(soup):\n",
        "    try:\n",
        "        y=[i.get('name') for i in soup.findAll('meta')]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "        z=np.c_[y,v]\n",
        "        return list2string(z)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_metadata_content(soup):\n",
        "    try:\n",
        "        v=[]\n",
        "        v=[i.get('content') for i in soup.findAll('meta')]\n",
        "    #     return list2string(v)\n",
        "        return (v)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_text(soup):\n",
        "    text=\"\"\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            text+=item.get_text()+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return text\n",
        "#     return (len(text.split())/COUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s9-_I0V1wnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_count(soup):\n",
        "    text=\"\"\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            text+=item.get_text()+\" \"\n",
        "    except:\n",
        "        pass\n",
        "    return len(text.split())\n",
        "\n",
        "def get_para_count(soup):\n",
        "    count=0\n",
        "    try:\n",
        "        for item in list(soup.find_all('p')):  #[:2]:\n",
        "            count+=1\n",
        "    except:\n",
        "        pass\n",
        "    return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtSpyUhG10U5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_internal_links(url_main,links):\n",
        "    internal_url_list=[]\n",
        "    try:\n",
        "        for item in links:\n",
        "            for url_parts in url_main.split('.')[:-1]:\n",
        "                if (url_parts in item.lower()):\n",
        "                    internal_url_list.append(item)\n",
        "        internal_url_list=list(dict.fromkeys(internal_url_list))    \n",
        "        return(len(internal_url_list))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def get_external_links(url_main,links):\n",
        "    external_url_list=[]\n",
        "    try:\n",
        "        for item in links:\n",
        "            count=0\n",
        "            for url_parts in url_main.split('.')[:-1]:\n",
        "                if (item.startswith(('http', 'ftp', 'www')) and (url_parts not in item.lower())):\n",
        "                    count+=1\n",
        "            if count==len(url_main.split('.')[:-1]):\n",
        "                external_url_list.append(item)\n",
        "        return(len(external_url_list))\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noWAhteO14Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(url):\n",
        "    # create a new Chrome session\n",
        "    try:\n",
        "        print(url)\n",
        "        metadata_property=''\n",
        "        metadata_name=''\n",
        "        metadata_content=''\n",
        "        title=''\n",
        "        word_count=0\n",
        "        sen_count=0\n",
        "        internal_links=0\n",
        "        external_links=0\n",
        "    #         driver = webdriver.Chrome(executable_path=r'D:/chromedriver_win32/chromedriver.exe')\n",
        "    #         driver.set_page_load_timeout(60)\n",
        "    #         driver.get(url)\n",
        "    #         html = driver.page_source\n",
        "    #         driver.close()\n",
        "    #         soup = BeautifulSoup(html, 'html.parser')  #Parse html code       \n",
        "    #         body = soup.find('body')\n",
        "\n",
        "        html= extract_html(url, 100)\n",
        "        soup = BeautifulSoup(html, 'lxml')\n",
        "        body = soup.find('body')\n",
        "        remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "                                             \"svg\", \"h1\",\"h2\", \"h3\", \"h4\", \"h5\", \"xml\"])]\n",
        "        text = \"\"\n",
        "        boilerpipe_sentences=\"\"\n",
        "        boilerpipe_content = prepare_sentences(Extractor(extractor='CanolaExtractor', html=html).getText())\n",
        "        boilerpipe_sentences = prepare_sentences(boilerpipe_content)\n",
        "    #         print('Sentences:',len(boilerpipe_sentences))\n",
        "\n",
        "#         p = '(?:http.*://)?(?:www.)?(?P<host>[^/ ]+).?(?P<port>[0-9]*).*'\n",
        "        p = '(?:http.*://)?(?:www[0-9].|www.)?(?P<host>[^/ ]+).?(?P<port>[0-9]*).*'\n",
        "        m = re.search(p,url)\n",
        "        url_main = m.group('host') # 'www.abc.com'\n",
        "\n",
        "\n",
        "\n",
        "    #         return pd.Series([get_metadata_property(soup),get_metadata_name(soup),get_metadata_content(soup),\n",
        "    #                           get_title(soup),len(nltk.word_tokenize(boilerpipe_sentences)),\n",
        "    #                           len(nltk.sent_tokenize(boilerpipe_sentences)),\n",
        "    #                           get_internal_links(url_main,links),\n",
        "    #                           get_external_links(url_main,links)])\n",
        "\n",
        "        print(len(soup))\n",
        "        if len(soup)>0:\n",
        "            metadata_property=get_metadata_property(soup)\n",
        "            metadata_name=get_metadata_name(soup)\n",
        "            metadata_content=get_metadata_content(soup)\n",
        "            title=get_title(soup)\n",
        "            \n",
        "            word_count=len(nltk.word_tokenize(boilerpipe_sentences))\n",
        "            \n",
        "            sen_count=len(nltk.sent_tokenize(boilerpipe_sentences))       \n",
        "\n",
        "            links = [ x['href'] for x in soup.find_all('a', href=True) ]\n",
        "            if len(links)>0:\n",
        "                internal_links=get_internal_links(url_main,links)\n",
        "                external_links=get_external_links(url_main,links)\n",
        "\n",
        "    #         return pd.Series([get_metadata_property(soup),get_metadata_name(soup),get_metadata_content(soup),\n",
        "    #                       get_title(soup)])\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    extract= pd.Series([metadata_property,metadata_name,metadata_content,\n",
        "                          title,word_count,sen_count,internal_links,external_links])\n",
        "    #         extract= pd.Series([get_metadata_property(soup),get_metadata_name(soup)])\n",
        "    print(extract)\n",
        "    return extract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nURhD1_6Fsph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test=pd.DataFrame(pd.Series([boilerpipe_sentences,0,0,0,0,0,0]),columns=['category','label_1',\t'label_3',\t'label_5',\t'label_6',\t'label_7',\t'label_8'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEYFjD9AHUlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fastai_bert_vocab = Vocab(list(bert_tok.vocab.keys()))\n",
        "fastai_tokenizer = Tokenizer(tok_func=FastAiBertTokenizer(bert_tok, max_seq_len=config.max_seq_len), pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "23T7UxDTXIoQ",
        "colab": {}
      },
      "source": [
        "sample=False\n",
        "DATA_ROOT=Path('/content/drive/My Drive/Data/DMOZ')\n",
        "df = pd.read_csv(DATA_ROOT / \"train.csv\")\n",
        "try:\n",
        "  df.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
        "except:\n",
        "  pass\n",
        "df.dropna(inplace=True)\n",
        "df['cat_id']=df['cat_id'].astype(int)\n",
        "if sample==True:\n",
        "  df_sample=df[df['cat_id']<9]\n",
        "  train=pd.concat([df_sample,pd.get_dummies(df_sample['cat_id'], prefix='label')],axis=1)\n",
        "  df=df_sample\n",
        "else:  \n",
        "  # train=df \n",
        "  train=pd.concat([df,pd.get_dummies(df['cat_id'], prefix='label')],axis=1) \n",
        "val=train\n",
        "\n",
        "del df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d6XCUwPuXIRh",
        "colab": {}
      },
      "source": [
        "train.sample(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KvuYhtOuXHym",
        "colab": {}
      },
      "source": [
        "# label_cols=['label_1',\t'label_3',\t'label_5',\t'label_6',\t'label_7',\t'label_8']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eji8RpszXGgJ",
        "outputId": "f9227638-61b7-4813-e8bc-c17e2e8659a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "url='https://www.amazon.com/'\n",
        "html= extract_html(url, 60)\n",
        "soup = BeautifulSoup(html, 'lxml')\n",
        "body = soup.find('body')\n",
        "# remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "#                                      \"svg\", \"h1\",\"h2\", \"h3\", \"h4\", \"h5\", \"xml\"])]\n",
        "remove = [s.extract() for s in body([\"script\", \"style\",\"iframe\",\"noscript\",\"nav\",\"footer\",\"header\",\\\n",
        "                                     \"svg\", \"xml\"])]\n",
        "boilerpipe_content = prepare_sentences(Extractor(extractor='CanolaExtractor', html=html).getText())\n",
        "boilerpipe_sentences = prepare_sentences(boilerpipe_content)\n",
        "nltk.sent_tokenize(boilerpipe_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Try Prime Deliver toMountainview 94035 12 Days of Deals Best Sellers Find a Gift Customer Service New Releases Registry Gift Cards Sell AmazonBasics Coupons Whole Foods Free Shipping Shopper Toolkit #FoundItOnAmazon Welcome to Amazon.',\n",
              " 'com.',\n",
              " 'If you prefer a simplified shopping experience, try the mobile web version of Amazon at www.',\n",
              " 'amazon.',\n",
              " 'com/access.',\n",
              " 'The mobile web version is similar to the mobile app.',\n",
              " 'Stay on Amazon.',\n",
              " 'com for access to all the features of the main Amazon website.',\n",
              " 'Learn more about Amazon Prime.',\n",
              " 'Prime members enjoy FREE Two-Day Delivery and exclusive access to music, movies, TV shows, original audio series, and Kindle books.',\n",
              " 'View or edit your browsing history After viewing product detail pages, look here to find an easy way to navigate back to pages you are interested in.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGjvOWbVnkAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_labels=6\n",
        "label_cols=[]\n",
        "num_labels=train['cat_id'].nunique()\n",
        "\n",
        "data={'cat_id':[0],\n",
        "      'category':[boilerpipe_sentences],\n",
        "}\n",
        "test=pd.DataFrame(data)\n",
        "for labels in train['cat_id'].unique():\n",
        "  label='label_'+str(labels)\n",
        "  label_cols.append(label)\n",
        "  test[label]=0\n",
        "\n",
        "test=test.append(test)\n",
        "test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55yUinrREYnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train=train.head(5)\n",
        "# val=train\n",
        "databunch = BertDataBunch.from_df(\".\", train, val, test,\n",
        "                  tokenizer=fastai_tokenizer,\n",
        "                  vocab=fastai_bert_vocab,\n",
        "                  text_cols=\"category\",\n",
        "                  label_cols=label_cols,\n",
        "                  bs=config.bs,\n",
        "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oloFk5SuG0J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.modeling import BertConfig, BertForSequenceClassification\n",
        "bert_model = BertForSequenceClassification.from_pretrained(config.bert_model_name, num_labels=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzqjoeEJG_Ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H27LaDdwDnkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import *\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "learner = Learner(\n",
        "    databunch, bert_model,\n",
        "    loss_func=loss_func\n",
        ")\n",
        "# if config.use_fp16: learner = learner.to_fp16()\n",
        "learner.to_fp32()\n",
        "learner.load(file=DATA_ROOT/'Model_DMOZ(6_cat).pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNAszFaPJfQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euvWEhnnJalS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLQiaB0wGoCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission=test\n",
        "for label in label_cols:\n",
        "  sample_submission[label]=0\n",
        "sample_submission[label_cols] = test_preds\n",
        "# sample_submission.to_csv(DATA_ROOT /\"predictions_1.csv\", index=False)\n",
        "# sample_submission.sample(10000).to_csv(DATA_ROOT /\"predictions_sample.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZvMg_NrJOZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUAuQKPKcaaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output=sample_submission.head(1).drop(columns=['cat_id','category']).T\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYLF5KmmfmXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output[0]=output[0].astype(float)\n",
        "output.nlargest(3,[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZHDV1SeX2_L",
        "colab_type": "code",
        "outputId": "ff57db0a-0f5a-42a8-fc4f-6d852e98222f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "DATA_ROOT=Path('/content/drive/My Drive/Data/DMOZ')\n",
        "# learner.load(file=DATA_ROOT/'Model_DMOZ(6_cat).pkl')\n",
        "learn = load_learner(DATA_ROOT, 'Model_DMOZ(6_cat).pkl')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMIQbNBMYn-0",
        "colab_type": "code",
        "outputId": "a7441b13-fff4-4c62-eec6-9baa3309bc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "learn.to_fp32()\n",
        "learn.predict(boilerpipe_sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(MultiCategory label_3,\n",
              " tensor([0., 1., 0., 0., 0., 0.]),\n",
              " tensor([0.0496, 0.7276, 0.1668, 0.0226, 0.0220, 0.0204]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hYQ6wlZZNyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}